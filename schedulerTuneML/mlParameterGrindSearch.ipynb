{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neurális háló építéséhez felhasznált program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import joblib\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testLocations = [\n",
    "    \"./parametertestResults/sampleprogram.json\",\n",
    "    \"./parametertestResults/ebizzy.json\",\n",
    "    \"./parametertestResults/ctx-clock.json\",\n",
    "    \"./parametertestResults/fs_mark.json\",\n",
    "    \"./parametertestResults/stream.json\",\n",
    "    \"./parametertestResults/glmark2.json\"\n",
    "]\n",
    "testNameList = [\n",
    "    \"sampleprogram\",\n",
    "    \"ebizzy\",\n",
    "    \"ctx-clock\",\n",
    "    \"fs_mark\",\n",
    "    \"stream\",\n",
    "    \"glmark2\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avgLst(lst):\n",
    "    if(isinstance(lst,list)):\n",
    "        return sum(lst)/len(lst)\n",
    "    else:\n",
    "        return lst\n",
    "\n",
    "def getIntervals(data):\n",
    "    intervalTop,intervalBottom = 0.0,float(avgLst(data[\"measurements\"][0][\"results\"]))\n",
    "    for j in data[\"measurements\"]:\n",
    "        if(float(avgLst(j[\"results\"])) > intervalTop):\n",
    "            intervalTop = float(avgLst(j[\"results\"]))\n",
    "        if(float(avgLst(j[\"results\"])) < intervalBottom):\n",
    "            intervalBottom = float(avgLst(j[\"results\"]))\n",
    "    minMaxLst = [intervalBottom,intervalTop]\n",
    "    return minMaxLst\n",
    "\n",
    "def featureScale(value,intervalMax,intervalMin):\n",
    "    return (value-intervalMin)/(intervalMax-intervalMin)\n",
    "\n",
    "def getPredictionDf(predictions_lst,tType,df):\n",
    "    return df[(df[\"testType\"]==tType) & (df[\"latency\"]==predictions[0][0]) &(df[\"min_gran\"]==predictions[0][1]) &(df[\"wakeup_gran\"]==predictions[0][2]) &(df[\"priority\"]==predictions[0][3]) & (df[\"vm.swappiness\"]==predictions[0][4]) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classResultIntervals = [0.20,0.4,0.6,0.8]\n",
    "classIntervalMinMax = []\n",
    "dataStrLst = []\n",
    "for i in range(len(testLocations)):\n",
    "    file = open(testLocations[i])\n",
    "    data = json.load(file)\n",
    "    dataStrLst.append(json.dumps(data))\n",
    "    minMax = getIntervals(data)\n",
    "    if(i == 0 or i == 2):\n",
    "        minMax.reverse()\n",
    "    classIntervalMinMax.append(minMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataSet = []\n",
    "for i in range(len(dataStrLst)):\n",
    "    data_json = json.loads(dataStrLst[i])\n",
    "    classResult = 0\n",
    "    for j in data_json[\"measurements\"]:\n",
    "        swap = 1 if ( int(j[\"parameters\"][\"vm.swap\"]) > 0 ) else 0                                     \n",
    "        testType = data_json[\"testType\"]\n",
    "        testName = data_json[\"testName\"]\n",
    "        batchProcess = 1 if ( int(j[\"parameters\"][\"prio\"]) > 0 ) else 0\n",
    "        serverWorkload = 1 if( int(j[\"parameters\"][\"min_gran\"]) > 1500000) else 0\n",
    "        resultNormalized = featureScale(float(avgLst(j[\"results\"])),classIntervalMinMax[i][1],classIntervalMinMax[i][0])\n",
    "        for k in range(len(classResultIntervals)):\n",
    "            if(resultNormalized > classResultIntervals[k]):\n",
    "                classResult = (k+1)\n",
    "        dataSet.append([testType,testName,batchProcess,classResult,serverWorkload,swap,resultNormalized,int(j[\"parameters\"][\"latency\"]),int(j[\"parameters\"][\"min_gran\"]),int(j[\"parameters\"][\"wakeup_gran\"]),int(j[\"parameters\"][\"prio\"]),int(j[\"parameters\"][\"vm.swap\"])],)\n",
    "df = pd.DataFrame(dataSet,columns=[\"testType\",\"testName\",\"batchProcess\",\"resultClass\",\"serverWorkload\",\"swap\",\"results\",\"latency\",\"min_gran\",\"wakeup_gran\",\"priority\",\"vm.swappiness\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testTypeMap = {\n",
    "    \"cpu-s\":0,\n",
    "    \"cpu\" : 1,\n",
    "    \"system\" : 2,\n",
    "    \"disk\" : 3,\n",
    "    \"memory\" : 4,\n",
    "    \"graphics\":5\n",
    "}\n",
    "df.testType.replace(to_replace=testTypeMap,inplace=True)\n",
    "#features\n",
    "X = df[[\"testType\",\"resultClass\",\"batchProcess\",\"serverWorkload\",\"swap\"]]\n",
    "#labels\n",
    "y = df[[\"latency\",\"min_gran\",\"wakeup_gran\",\"priority\",\"vm.swappiness\"]]\n",
    "#split dataset 80% train 20% test\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#végig próbálja ezekkel a beállításokkal betanítani a modelt\n",
    "params = {\n",
    "            'estimator__activation' : ['identity', 'logistic', 'tanh', 'relu'],\n",
    "            'estimator__solver' : ['lbfgs', 'sgd', 'adam'],\n",
    "            'estimator__hidden_layer_sizes': [(1,),(2,),(3,),(4,),(5,),(6,),(7,),(8,),(9,),(10,),(11,), (12,),(13,),(14,),(15,),(16,),(17,),(18,),(19,),(20,),(21,)]\n",
    "}\n",
    "\n",
    "model = GridSearchCV( MultiOutputClassifier(MLPClassifier(random_state=0,max_iter=10000000)) ,param_grid=params)\n",
    "model.fit(X_train,y_train)\n",
    "#végül kíirja a legjobb paraméterkészletet\n",
    "print(\"A fejlesztési készleten található legjobb paraméterkészlet:\")\n",
    "print(model.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Program kimenete: \n",
    "{'estimator__activation': 'tanh', 'estimator__hidden_layer_sizes': (9,), 'estimator__solver': 'lbfgs'}\n",
    "\n",
    "\n",
    "Ezeket fogom felhasználni a model építéséhez. Sajnos nincs mágikus képlet a rejtett rétegek neuronjainak optimális számának kiválasztására. Létezik néhány \"thumb rule\" a neuronok számainak meghatározásához.\n",
    "Találtam egy szabályt, miszerint a felső korlát meghatározására használható a következő képlet:\n",
    "\\begin{equation}\n",
    "N_h = \\frac{N_s} {(\\alpha * (N_i + N_o))}\n",
    "\\end{equation}\n",
    "Ahol \n",
    "* $N_i$  = az input neuronok száma.\n",
    "* $N_o$ = az output neuronok száma.\n",
    "* $N_s$ = a tanító minták száma\n",
    "* $\\alpha$ = egy tetszőleges méretezési tényező, általában 2-10.\n",
    "\n",
    "Egy durva közelítés a geometriai piramisszabály segítségével nyerhető. Egy három rétegű hálózat esetén, ahol $n$ a bemenetek száma és $m$ a kimeneti elemek számát jelöli, a szabály így néz ki: $\\sqrt{n*m}$.\n",
    "A program nekem 9 neuront választott a legjobbnak, ez a piramisszabályhoz viszonylag közeli érték."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
